{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6d3388-e8e3-4f18-b027-01663d638cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.9600\n",
      "Model saved as model.pkl\n",
      "Imputer saved as imputer.pkl\n",
      "Scaler saved as scaler.pkl\n",
      "Target distribution:\n",
      " Target\n",
      "0    458\n",
      "1    241\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train_model.py\n",
    "\"\"\"\n",
    "This script trains a K-Nearest Neighbors (KNN) classifier to predict breast cancer malignancy\n",
    "using the Breast Cancer Wisconsin (Original) dataset from the UCI repository. It handles data\n",
    "cleaning, imputation, scaling, model training, evaluation, and finally saves all components\n",
    "(model, imputer, scaler) for later use in deployment.\n",
    "\"\"\"\n",
    "\n",
    "# === Step 1: Import libraries ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# === Step 2: Load the dataset ===\n",
    "dataset = fetch_ucirepo(id=15)  # Breast Cancer Wisconsin (Original)\n",
    "data = pd.concat([dataset.data.features, dataset.data.targets], axis=1)\n",
    "data.rename(columns={'Class': 'Target'}, inplace=True)\n",
    "data['Target'] = data['Target'].map({2: 0, 4: 1})  # Benign: 0, Malignant: 1\n",
    "\n",
    "# === Step 3: Separate features and labels ===\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# === Step 4: Impute missing values ===\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# === Step 5: Train/test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imputed, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# === Step 6: Scale the features ===\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# === Step 7: Train KNN model ===\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# === Step 8: Evaluate accuracy ===\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# === Step 9: Save the model ===\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model saved as model.pkl\")\n",
    "\n",
    "# === Step 10: Save the imputer ===\n",
    "with open(\"imputer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(imputer, f)\n",
    "print(\"Imputer saved as imputer.pkl\")\n",
    "\n",
    "# === Step 11: Save the scaler ===\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Scaler saved as scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1597f1-6455-4cf5-a1e0-1c3ac4ff0ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
