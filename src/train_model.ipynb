{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6d3388-e8e3-4f18-b027-01663d638cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching dataset from UCI repository...\n",
      "Preparing dataset...\n",
      "Imputing missing values...\n",
      "Scaling feature values...\n",
      "Splitting data into training and testing sets...\n",
      "Training K-Nearest Neighbors classifier...\n",
      "Evaluating model...\n",
      "Model accuracy with 5 features: 0.9600\n",
      "Saving model and scaler to 'breast_cancer_model.pkl'...\n",
      "✅ Training complete. Model is ready for deployment.\n"
     ]
    }
   ],
   "source": [
    "# train_model.py\n",
    "\"\"\"\n",
    "Trains a K-Nearest Neighbors (KNN) model on selected features from the Breast Cancer Wisconsin (Original) dataset.\n",
    "This script includes data preprocessing, scaling, model training, evaluation, and saving the trained model for deployment.\n",
    "It is specifically configured for a simplified input of 5 features to align with a Flask web application form.\n",
    "\n",
    "Steps:\n",
    "1. Download the dataset directly from the UCI repository using `ucimlrepo`.\n",
    "2. Select 5 relevant features to simplify user input.\n",
    "3. Handle missing values with mean imputation.\n",
    "4. Standardize feature values using `StandardScaler` to improve KNN performance.\n",
    "5. Split the dataset into training and testing subsets.\n",
    "6. Train a K-Nearest Neighbors model (k=5).\n",
    "7. Evaluate the model's performance.\n",
    "8. Save both the trained model and scaler into a `.pkl` file for use in the Flask app.\n",
    "\n",
    "This is designed for use in a Flask CI/CD deployment pipeline.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd  # Data manipulation\n",
    "from sklearn.model_selection import train_test_split  # Splitting dataset into train/test\n",
    "from sklearn.impute import SimpleImputer  # Handling missing values\n",
    "from sklearn.preprocessing import StandardScaler  # Normalizing input data\n",
    "from sklearn.neighbors import KNeighborsClassifier  # KNN classifier\n",
    "from sklearn.metrics import accuracy_score  # Evaluate model accuracy\n",
    "from ucimlrepo import fetch_ucirepo  # Fetch UCI dataset\n",
    "import pickle  # Save trained model and scaler to file\n",
    "\n",
    "# === Step 1: Load the Breast Cancer dataset from UCI ===\n",
    "print(\"Fetching dataset from UCI repository...\")\n",
    "dataset = fetch_ucirepo(id=15)  # ID 15 is the Breast Cancer Wisconsin (Original) dataset\n",
    "\n",
    "# Combine features and target column into one DataFrame\n",
    "print(\"Preparing dataset...\")\n",
    "data = pd.concat([dataset.data.features, dataset.data.targets], axis=1)\n",
    "data.rename(columns={'Class': 'Target'}, inplace=True)  # Rename 'Class' to 'Target' for clarity\n",
    "\n",
    "# Convert labels from (2 = benign, 4 = malignant) to (0 = benign, 1 = malignant)\n",
    "data['Target'] = data['Target'].map({2: 0, 4: 1})\n",
    "\n",
    "# === Step 2: Select 5 features to match the web form ===\n",
    "# NOTE: The actual column names use underscores (_) instead of spaces.\n",
    "selected_features = [\n",
    "    'Clump_thickness',\n",
    "    'Uniformity_of_cell_size',\n",
    "    'Uniformity_of_cell_shape',\n",
    "    'Marginal_adhesion',\n",
    "    'Single_epithelial_cell_size'\n",
    "]\n",
    "X = data[selected_features]  # Feature set\n",
    "y = data['Target']           # Target labels\n",
    "\n",
    "# === Step 3: Handle missing values using mean imputation ===\n",
    "print(\"Imputing missing values...\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=selected_features)\n",
    "\n",
    "# === Step 4: Scale features using StandardScaler ===\n",
    "print(\"Scaling feature values...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# === Step 5: Split data into training and testing sets ===\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# === Step 6: Train the KNN classifier (k=5) ===\n",
    "print(\"Training K-Nearest Neighbors classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# === Step 7: Evaluate model accuracy ===\n",
    "print(\"Evaluating model...\")\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy with 5 features: {accuracy:.4f}\")\n",
    "\n",
    "# === Step 8: Save trained model and scaler to file ===\n",
    "print(\"Saving model and scaler to 'breast_cancer_model.pkl'...\")\n",
    "with open('breast_cancer_model.pkl', 'wb') as f:\n",
    "    pickle.dump((model, scaler), f)\n",
    "\n",
    "print(\"✅ Training complete. Model is ready for deployment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1597f1-6455-4cf5-a1e0-1c3ac4ff0ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
